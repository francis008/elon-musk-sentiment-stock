{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32aef487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd495ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig_tweet_id', 'orig_tweet_created_at', 'orig_tweet_text',\n",
      "       'orig_tweet_url', 'orig_tweet_twitter_url', 'orig_tweet_username',\n",
      "       'orig_tweet_retweet_count', 'orig_tweet_reply_count',\n",
      "       'orig_tweet_like_count', 'orig_tweet_quote_count',\n",
      "       'orig_tweet_view_count', 'orig_tweet_bookmark_count', 'musk_tweet_id',\n",
      "       'musk_quote_tweet', 'musk_quote_retweet_count',\n",
      "       'musk_quote_reply_count', 'musk_quote_like_count',\n",
      "       'musk_quote_quote_count', 'musk_quote_view_count',\n",
      "       'musk_quote_bookmark_count', 'musk_quote_created_at', 'vader_compund',\n",
      "       'vader_label', 'vader_compound', 'tweet_date', 'musk_quote_date',\n",
      "       'Date_', 'Close_TSLA', 'next_trading_day', 'next_day_close',\n",
      "       'pct_change_next_day', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/musk_tweets_with_tsla_return.csv\")\n",
    "df = df.dropna(subset=[\"pct_change_next_day\"])\n",
    "df[\"target\"] = (df[\"pct_change_next_day\"] > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8e54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['vader_compound',\n",
    "    'musk_quote_like_count',\n",
    "    'musk_quote_retweet_count',\n",
    "    'musk_quote_quote_count',\n",
    "    'musk_quote_view_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40f22631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d87b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [23:31:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5311601150527325\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       563\n",
      "           1       0.49      0.42      0.45       480\n",
      "\n",
      "    accuracy                           0.53      1043\n",
      "   macro avg       0.52      0.52      0.52      1043\n",
      "weighted avg       0.53      0.53      0.53      1043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[351 212]\n",
      " [277 203]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ffd200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load FinBERT\n",
    "finbert_model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Create sentiment pipeline\n",
    "finbert_pipeline = pipeline(\"sentiment-analysis\", model=finbert_model, tokenizer=finbert_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45b744d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finbert_sentiment(text):\n",
    "    try:\n",
    "        result = finbert_pipeline(text[:512])  # max 512 tokens\n",
    "        label = result[0]['label'].lower()     # 'positive', 'negative', 'neutral'\n",
    "        score = result[0]['score']\n",
    "        return pd.Series([label, score])\n",
    "    except:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# Apply to your dataset\n",
    "df[['finbert_label', 'finbert_score']] = df['musk_quote_tweet'].apply(get_finbert_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "518547e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     musk_quote_tweet finbert_label  \\\n",
      "0                                                 Yup       neutral   \n",
      "1                         Massive public manipulation       neutral   \n",
      "3                                                  ü§£ü§£       neutral   \n",
      "4                                           Prescient       neutral   \n",
      "6        Congratulations Tesla team on a great year!!      positive   \n",
      "7                             Improved longform posts      positive   \n",
      "8                                     Prelude to Mars       neutral   \n",
      "9                Key milestone completed for flight 2       neutral   \n",
      "10  ‚ÄúAds‚Äù like this where you learn or are enterta...       neutral   \n",
      "12              Great conversation with @NarendraModi       neutral   \n",
      "14  Once again, I‚Äôd like to offer this platform to...       neutral   \n",
      "15                                               Bold       neutral   \n",
      "16                             Why ESG is the devil ‚Ä¶       neutral   \n",
      "17                                     Big difference       neutral   \n",
      "18  It‚Äôd be great to have @maddow, @donlemon &amp;...       neutral   \n",
      "19                            Great to work with you!      positive   \n",
      "20  Would be great to have shows from all parts of...       neutral   \n",
      "21                                             On now       neutral   \n",
      "23                     Every parent should watch this       neutral   \n",
      "24                     38 astronauts to orbit so far!       neutral   \n",
      "26  Lot of noise about @RonDeSantis announcing &am...       neutral   \n",
      "27                    Congratulations Neuralink team!      positive   \n",
      "28                  üá∫üá∏üá∫üá∏ Untamed Free Speech FTW üá∫üá∏üá∫üá∏       neutral   \n",
      "29  And works almost everywhere on Earth with glob...       neutral   \n",
      "30                         One hell of a plasma beam!       neutral   \n",
      "31  Walter is incredibly thorough in his research....       neutral   \n",
      "32  Was the Internet Archive manipulated for nepot...      negative   \n",
      "33  Love to see Starlink providing great connectiv...       neutral   \n",
      "34                 Tesla shareholder meeting underway       neutral   \n",
      "35  As more satellites &amp; ground stations are a...      positive   \n",
      "36  Tesla Powerwall does the seem for individual h...       neutral   \n",
      "40  I am excited to welcome Linda Yaccarino as the...      positive   \n",
      "41  Super easy to use Starlink out of the box, no ...       neutral   \n",
      "42                                       Thanks Dave!       neutral   \n",
      "43                 Congratulations Tesla Texas Team!!      positive   \n",
      "44  On this platform, unlike the one-way street of...       neutral   \n",
      "45                         WhatsApp cannot be trusted       neutral   \n",
      "46                           Livestream starting soon       neutral   \n",
      "48                                    Sunset in space       neutral   \n",
      "51  Content creators can now enable subscriptions ...       neutral   \n",
      "52  Anyone making materially false statements on t...       neutral   \n",
      "53                                    Or maybe just X       neutral   \n",
      "54  We‚Äôre rapidly improving transparency &amp; fai...      positive   \n",
      "56                               10 minutes to launch       neutral   \n",
      "57             All systems currently green for launch       neutral   \n",
      "59              Success maybe, excitement guaranteed!       neutral   \n",
      "60                                        @NPR Hello?       neutral   \n",
      "61            This time with video &amp; better audio      positive   \n",
      "62              Penetrating deep &amp; hard with @BBC       neutral   \n",
      "64  Starship is stacked &amp; ready to launch next...       neutral   \n",
      "\n",
      "    finbert_score  \n",
      "0        0.903860  \n",
      "1        0.735013  \n",
      "3        0.905219  \n",
      "4        0.938116  \n",
      "6        0.766192  \n",
      "7        0.957461  \n",
      "8        0.910416  \n",
      "9        0.899326  \n",
      "10       0.929626  \n",
      "12       0.860082  \n",
      "14       0.776064  \n",
      "15       0.902758  \n",
      "16       0.882332  \n",
      "17       0.873821  \n",
      "18       0.847638  \n",
      "19       0.711206  \n",
      "20       0.822497  \n",
      "21       0.901616  \n",
      "23       0.925957  \n",
      "24       0.795651  \n",
      "26       0.904882  \n",
      "27       0.513276  \n",
      "28       0.943698  \n",
      "29       0.848127  \n",
      "30       0.879816  \n",
      "31       0.798147  \n",
      "32       0.641133  \n",
      "33       0.793007  \n",
      "34       0.914728  \n",
      "35       0.835600  \n",
      "36       0.946811  \n",
      "40       0.496004  \n",
      "41       0.865187  \n",
      "42       0.705362  \n",
      "43       0.539536  \n",
      "44       0.857894  \n",
      "45       0.899104  \n",
      "46       0.932875  \n",
      "48       0.894086  \n",
      "51       0.862885  \n",
      "52       0.824130  \n",
      "53       0.842394  \n",
      "54       0.756632  \n",
      "56       0.929270  \n",
      "57       0.931901  \n",
      "59       0.740247  \n",
      "60       0.915666  \n",
      "61       0.901110  \n",
      "62       0.901416  \n",
      "64       0.862095  \n"
     ]
    }
   ],
   "source": [
    "print(df[['musk_quote_tweet', 'finbert_label', 'finbert_score']].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cbbe146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Map label to numerical value\n",
    "sentiment_map = {'positive': 1, 'neutral': 0, 'negative': -1}\n",
    "df['finbert_label_num'] = df['finbert_label'].map(sentiment_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43da6d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'finbert_label_num',\n",
    "    'musk_quote_like_count',\n",
    "    'musk_quote_retweet_count',\n",
    "    'musk_quote_quote_count',\n",
    "    'musk_quote_view_count'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f89a4dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [23:56:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5071907957813998\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.61      0.57       563\n",
      "           1       0.46      0.38      0.42       480\n",
      "\n",
      "    accuracy                           0.51      1043\n",
      "   macro avg       0.50      0.50      0.50      1043\n",
      "weighted avg       0.50      0.51      0.50      1043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[345 218]\n",
      " [296 184]]\n"
     ]
    }
   ],
   "source": [
    "X = df[features]\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c951f780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use mps:0\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "# Load Twitter-RoBERTa model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create a pipeline for sentiment\n",
    "twitter_sentiment = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5270d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the labels returned by Twitter-RoBERTa\n",
    "def classify_roberta_sentiment(text):\n",
    "    try:\n",
    "        result = twitter_sentiment(text[:512])[0]  # BERT limit\n",
    "        label_map = {'LABEL_0': 'negative', 'LABEL_1': 'neutral', 'LABEL_2': 'positive'}\n",
    "        score_map = {'LABEL_0': -1, 'LABEL_1': 0, 'LABEL_2': 1}\n",
    "        label = label_map[result['label']]\n",
    "        score = score_map[result['label']] * result['score']  # Score weighted by direction\n",
    "        return pd.Series([label, score])\n",
    "    except:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# Apply to your dataset\n",
    "df[['roberta_label', 'roberta_score']] = df['musk_quote_tweet'].apply(classify_roberta_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ca43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hybrid_sentiment'] = (\n",
    "    0.5 * df['vader_compound'] + \n",
    "    0.5 * df['roberta_score']\n",
    ")\n",
    "\n",
    "features_roberta = [\n",
    "    'roberta_score',\n",
    "    'musk_quote_like_count',\n",
    "    'musk_quote_retweet_count',\n",
    "    'musk_quote_quote_count',\n",
    "    'musk_quote_view_count'\n",
    "]\n",
    "\n",
    "features_hybrid = [\n",
    "    'hybrid_sentiment',\n",
    "    'musk_quote_like_count',\n",
    "    'musk_quote_retweet_count',\n",
    "    'musk_quote_quote_count',\n",
    "    'musk_quote_view_count'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77acb8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Roberta-only Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:43:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5455417066155321\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.60       563\n",
      "           1       0.51      0.46      0.48       480\n",
      "\n",
      "    accuracy                           0.55      1043\n",
      "   macro avg       0.54      0.54      0.54      1043\n",
      "weighted avg       0.54      0.55      0.54      1043\n",
      "\n",
      "\n",
      " Hybrid (VADER + Roberta) Model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:43:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.513902205177373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.62      0.58       563\n",
      "           1       0.47      0.39      0.43       480\n",
      "\n",
      "    accuracy                           0.51      1043\n",
      "   macro avg       0.51      0.50      0.50      1043\n",
      "weighted avg       0.51      0.51      0.51      1043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_xgboost_experiment(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "X_roberta = df[features_roberta]\n",
    "X_hybrid = df[features_hybrid]\n",
    "y = (df['pct_change_next_day'] > 0).astype(int)\n",
    "\n",
    "print(\"Roberta-only Model:\")\n",
    "model_roberta = run_xgboost_experiment(X_roberta, y)\n",
    "\n",
    "print(\"\\n Hybrid (VADER + Roberta) Model:\")\n",
    "model_hybrid = run_xgboost_experiment(X_hybrid, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ff1f9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [00:57:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility Model Accuracy: 0.573346116970278\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.28      0.33       397\n",
      "           1       0.63      0.76      0.69       646\n",
      "\n",
      "    accuracy                           0.57      1043\n",
      "   macro avg       0.52      0.52      0.51      1043\n",
      "weighted avg       0.55      0.57      0.55      1043\n",
      "\n",
      "Confusion Matrix:\n",
      " [[110 287]\n",
      " [158 488]]\n"
     ]
    }
   ],
   "source": [
    "df[\"volatility_label\"] = (df['pct_change_next_day'].abs() > 0.02).astype(int)\n",
    "features = [\n",
    "    'roberta_score',\n",
    "    'vader_compound',\n",
    "    'musk_quote_like_count',\n",
    "    'musk_quote_retweet_count',\n",
    "    'musk_quote_quote_count',\n",
    "    'musk_quote_view_count'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['volatility_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Volatility Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
