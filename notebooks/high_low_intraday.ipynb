{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac91da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87f849e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/musk_quote_with_sentiment.csv\")\n",
    "df['musk_quote_created_at'] = pd.to_datetime(df['musk_quote_created_at'])\n",
    "start_date = df[\"musk_quote_created_at\"].min().date().isoformat()\n",
    "end_date = df[\"musk_quote_created_at\"].max().date().isoformat()\n",
    "ticker = \"TSLA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e3f57d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2015-06-29\n",
      "1      2015-06-30\n",
      "2      2015-07-01\n",
      "3      2015-07-02\n",
      "4      2015-07-06\n",
      "          ...    \n",
      "2458   2025-04-07\n",
      "2459   2025-04-08\n",
      "2460   2025-04-09\n",
      "2461   2025-04-10\n",
      "2462   2025-04-11\n",
      "Name: Date, Length: 2463, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tsla_df = yf.download(ticker, start=start_date, end=end_date)\n",
    "tsla_df = tsla_df.reset_index()\n",
    "tsla_df[\"Date\"] = pd.to_datetime(tsla_df[\"Date\"])\n",
    "print(tsla_df[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81d9bbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date_', 'Close_TSLA', 'High_TSLA', 'Low_TSLA', 'Open_TSLA',\n",
      "       'Volume_TSLA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "tsla_df = tsla_df.reset_index(drop=True)\n",
    "\n",
    "# Convert multi-level to single-level columns\n",
    "if tsla_df.columns.nlevels > 1:\n",
    "    tsla_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in tsla_df.columns]\n",
    "\n",
    "print(tsla_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac89f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_df[\"intraday_volatility\"] = (tsla_df[\"High_TSLA\"] - tsla_df[\"Low_TSLA\"]) / tsla_df[\"Open_TSLA\"]\n",
    "tsla_df[\"Date_\"] = pd.to_datetime(tsla_df[\"Date_\"])\n",
    "tsla_df[\"volatility_label\"] = (tsla_df[\"intraday_volatility\"] > 0.03).astype(int)\n",
    "\n",
    "tsla_df[['Date_', 'Open_TSLA', 'High_TSLA','Close_TSLA', 'Low_TSLA', 'intraday_volatility', 'volatility_label']].to_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/tsla_intraday_volatility.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a054afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tweet + sentiment dataset\n",
    "tweet_df = pd.read_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/musk_tweets_with_tsla_return.csv\")\n",
    "tweet_df['musk_quote_created_at'] = pd.to_datetime(tweet_df['musk_quote_created_at'])\n",
    "\n",
    "# Add tweet date for merge\n",
    "tweet_df['tweet_date'] = tweet_df['musk_quote_created_at'].dt.date\n",
    "tweet_df['tweet_date'] = pd.to_datetime(tweet_df['tweet_date'])\n",
    "# Load TSLA volatility data (from above)\n",
    "tsla_vol = pd.read_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/tsla_intraday_volatility.csv\")\n",
    "tsla_vol['Date_'] = pd.to_datetime(tsla_vol['Date_'])\n",
    "\n",
    "# Merge on date\n",
    "df = pd.merge(tweet_df, tsla_vol[['Date_', 'intraday_volatility', 'volatility_label']],\n",
    "              left_on='tweet_date', right_on='Date_', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66db3efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Load Twitter-RoBERTa model and tokenizer\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Create a pipeline for sentiment\n",
    "twitter_sentiment = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def classify_roberta_sentiment(text):\n",
    "    try:\n",
    "        result = twitter_sentiment(text[:512])[0]  # BERT limit\n",
    "        label_map = {'LABEL_0': 'negative', 'LABEL_1': 'neutral', 'LABEL_2': 'positive'}\n",
    "        score_map = {'LABEL_0': -1, 'LABEL_1': 0, 'LABEL_2': 1}\n",
    "        label = label_map[result['label']]\n",
    "        score = score_map[result['label']] * result['score']  # Score weighted by direction\n",
    "        return pd.Series([label, score])\n",
    "    except:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# Apply to your dataset\n",
    "df[['roberta_label', 'roberta_score']] = df['musk_quote_tweet'].apply(classify_roberta_sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e1b984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in target: 2048\n",
      "Percentage of NaN values: 28.16%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of NaN values in target: {df['volatility_label'].isna().sum()}\")\n",
    "print(f\"Percentage of NaN values: {df['volatility_label'].isna().mean() * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25347511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [02:10:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility Model Accuracy: 0.8535885167464115\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.29      0.08      0.13       137\n",
      "         1.0       0.87      0.97      0.92       908\n",
      "\n",
      "    accuracy                           0.85      1045\n",
      "   macro avg       0.58      0.53      0.52      1045\n",
      "weighted avg       0.80      0.85      0.82      1045\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 11 126]\n",
      " [ 27 881]]\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna(subset=['volatility_label'])\n",
    "features = [\n",
    "    'roberta_score',\n",
    "    'vader_compound',\n",
    "    'musk_quote_like_count',\n",
    "    'musk_quote_retweet_count',\n",
    "    'musk_quote_quote_count',\n",
    "    'musk_quote_view_count'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['volatility_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Volatility Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "32b189f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francis/Desktop/Github/elon-musk-sentiment-stock/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [02:16:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Volatility Model Accuracy: 0.5407166123778502\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.56      0.56       156\n",
      "         1.0       0.53      0.52      0.53       151\n",
      "\n",
      "    accuracy                           0.54       307\n",
      "   macro avg       0.54      0.54      0.54       307\n",
      "weighted avg       0.54      0.54      0.54       307\n",
      "\n",
      "Confusion Matrix:\n",
      " [[88 68]\n",
      " [73 78]]\n",
      "volatility_label\n",
      "1.0    0.5\n",
      "0.0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_major = df[df['volatility_label'] == 1]\n",
    "df_minor = df[df['volatility_label'] == 0]\n",
    "\n",
    "df_major_downsampled = resample(df_major, replace=False, n_samples=len(df_minor), random_state=42)\n",
    "df_balanced = pd.concat([df_major_downsampled, df_minor])\n",
    "\n",
    "X = df_balanced[features]\n",
    "y = df_balanced['volatility_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Balanced Volatility Model Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(df_balanced['volatility_label'].value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
