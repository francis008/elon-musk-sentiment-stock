{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c514528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db4091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/musk_quote_with_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cbb016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2023-05-09 16:50:16+00:00\n",
      "1      2023-05-09 16:12:06+00:00\n",
      "2      2023-04-15 20:42:55+00:00\n",
      "3      2023-04-12 19:07:08+00:00\n",
      "4      2023-03-27 01:57:41+00:00\n",
      "                  ...           \n",
      "7268   2024-12-03 13:36:24+00:00\n",
      "7269   2024-12-03 02:47:26+00:00\n",
      "7270   2024-12-03 02:10:20+00:00\n",
      "7271   2024-12-03 01:10:16+00:00\n",
      "7272   2024-12-03 00:20:24+00:00\n",
      "Name: musk_quote_created_at, Length: 7273, dtype: datetime64[ns, UTC]\n"
     ]
    }
   ],
   "source": [
    "df['musk_quote_created_at'] = pd.to_datetime(df['musk_quote_created_at'])\n",
    "print(df['musk_quote_created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "310a7e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date: 2015-06-27\n",
      "End date: 2025-04-13\n"
     ]
    }
   ],
   "source": [
    "ticker = \"TSLA\"\n",
    "start_date = df[\"musk_quote_created_at\"].min().date().isoformat()\n",
    "end_date = df[\"musk_quote_created_at\"].max().date().isoformat()\n",
    "print(f\"Start date: {start_date}\")\n",
    "print(f\"End date: {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6de01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2015-06-29\n",
      "1      2015-06-30\n",
      "2      2015-07-01\n",
      "3      2015-07-02\n",
      "4      2015-07-06\n",
      "          ...    \n",
      "2458   2025-04-07\n",
      "2459   2025-04-08\n",
      "2460   2025-04-09\n",
      "2461   2025-04-10\n",
      "2462   2025-04-11\n",
      "Name: Date, Length: 2463, dtype: datetime64[ns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tsla_df = yf.download(ticker, start=start_date, end=end_date)\n",
    "tsla_df = tsla_df.reset_index()\n",
    "tsla_df[\"Date\"] = pd.to_datetime(tsla_df[\"Date\"])\n",
    "print(tsla_df[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "680b9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "tsla_df = tsla_df.reset_index(drop=True)\n",
    "\n",
    "# Convert multi-level to single-level columns\n",
    "if tsla_df.columns.nlevels > 1:\n",
    "    tsla_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in tsla_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "24f24881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date_', 'Close_TSLA', 'High_TSLA', 'Low_TSLA', 'Open_TSLA',\n",
      "       'Volume_TSLA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(tsla_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4c5c1821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['orig_tweet_id', 'orig_tweet_created_at', 'orig_tweet_text',\n",
      "       'orig_tweet_url', 'orig_tweet_twitter_url', 'orig_tweet_username',\n",
      "       'orig_tweet_retweet_count', 'orig_tweet_reply_count',\n",
      "       'orig_tweet_like_count', 'orig_tweet_quote_count',\n",
      "       'orig_tweet_view_count', 'orig_tweet_bookmark_count', 'musk_tweet_id',\n",
      "       'musk_quote_tweet', 'musk_quote_retweet_count',\n",
      "       'musk_quote_reply_count', 'musk_quote_like_count',\n",
      "       'musk_quote_quote_count', 'musk_quote_view_count',\n",
      "       'musk_quote_bookmark_count', 'musk_quote_created_at', 'vader_compund',\n",
      "       'vader_label', 'vader_compound', 'tweet_date', 'musk_quote_date',\n",
      "       'Date_', 'Close_TSLA'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df['tweet_date'] = df['musk_quote_created_at'].dt.date\n",
    "df['tweet_date'] = pd.to_datetime(df['tweet_date'])\n",
    "merged_df = pd.merge(df, tsla_df[['Date_', 'Close_TSLA']], left_on='tweet_date', right_on='Date_', how='left')\n",
    "print(merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "72ae3fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  tweet_date      Date_  Close_TSLA next_trading_day  next_day_close  \\\n",
      "0 2023-05-09 2023-05-09  169.149994       2023-05-10      168.539993   \n",
      "1 2023-05-09 2023-05-09  169.149994       2023-05-10      168.539993   \n",
      "2 2023-04-15        NaT         NaN              NaT             NaN   \n",
      "3 2023-04-12 2023-04-12  180.539993       2023-04-13      185.899994   \n",
      "4 2023-03-27 2023-03-27  191.809998       2023-03-28      189.190002   \n",
      "5 2023-03-12        NaT         NaN              NaT             NaN   \n",
      "6 2024-01-02 2024-01-02  248.419998       2024-01-03      238.449997   \n",
      "7 2023-06-29 2023-06-29  257.500000       2023-06-30      261.769989   \n",
      "8 2023-06-27 2023-06-27  250.210007       2023-06-28      256.239990   \n",
      "9 2023-06-27 2023-06-27  250.210007       2023-06-28      256.239990   \n",
      "\n",
      "   pct_change_next_day  \n",
      "0            -0.003606  \n",
      "1            -0.003606  \n",
      "2                  NaN  \n",
      "3             0.029689  \n",
      "4            -0.013659  \n",
      "5                  NaN  \n",
      "6            -0.040134  \n",
      "7             0.016582  \n",
      "8             0.024100  \n",
      "9             0.024100  \n"
     ]
    }
   ],
   "source": [
    "# First create a mapping of each trading day to its next trading day\n",
    "next_trading_day = {}\n",
    "trading_days = tsla_df['Date_'].sort_values().tolist()\n",
    "\n",
    "for i in range(len(trading_days) - 1):\n",
    "    next_trading_day[trading_days[i]] = trading_days[i+1]\n",
    "\n",
    "# Apply this mapping to get the correct next day close\n",
    "# First create a dict of dates to closing prices\n",
    "date_to_close = dict(zip(tsla_df['Date_'], tsla_df['Close_TSLA']))\n",
    "\n",
    "# Then apply the mapping correctly\n",
    "df['tweet_date'] = pd.to_datetime(df['musk_quote_created_at']).dt.date\n",
    "df['tweet_date'] = pd.to_datetime(df['tweet_date'])\n",
    "\n",
    "# Create a proper merge\n",
    "merged_df = pd.merge(df, tsla_df[['Date_', 'Close_TSLA']], \n",
    "                    left_on='tweet_date', \n",
    "                    right_on='Date_', \n",
    "                    how='left')\n",
    "\n",
    "# Add next trading day\n",
    "merged_df['next_trading_day'] = merged_df['Date_'].map(next_trading_day)\n",
    "# Add next day's close using the mapping\n",
    "merged_df['next_day_close'] = merged_df['next_trading_day'].map(date_to_close)\n",
    "\n",
    "# Calculate percentage change\n",
    "merged_df['pct_change_next_day'] = (merged_df['next_day_close'] - merged_df['Close_TSLA']) / merged_df['Close_TSLA']\n",
    "\n",
    "# Check results\n",
    "print(merged_df[['tweet_date', 'Date_', 'Close_TSLA', 'next_trading_day', 'next_day_close', 'pct_change_next_day']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "96e5af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"/Users/francis/Desktop/Github/elon-musk-sentiment-stock/data/musk_tweets_with_tsla_return.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
